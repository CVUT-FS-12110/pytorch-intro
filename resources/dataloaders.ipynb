{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "507cd03b-ed88-4086-89a4-b7df2b8358ef",
   "metadata": {},
   "source": [
    "# Datasets and Dataloaders\n",
    "\n",
    "## Dataset\n",
    "- Acts as a **container** for raw data.\n",
    "- Provides access to **individual samples** via indexing (`dataset[idx]`).\n",
    "- Implements:\n",
    "  - `__len__`: Returns the size of the dataset.\n",
    "  - `__getitem__`: Fetches a single sample by index.\n",
    "- Does **not handle batching**, shuffling, or parallel loading.\n",
    "\n",
    "## DataLoader\n",
    "- Wraps a `Dataset` and acts as an **iterator** for easy data loading.\n",
    "- Provides **batches** of data for training or inference.\n",
    "- Handles:\n",
    "  - **Batching**: Combines multiple samples into batches.\n",
    "  - **Shuffling**: Randomizes the order of samples.\n",
    "  - **Parallel loading**: Uses multiple worker threads or processes to load data.\n",
    "- Implements:\n",
    "  - `__iter__`: Returns an iterator that fetches batches.\n",
    " \n",
    "## Summary\n",
    "| Feature              | `Dataset`                | `DataLoader`            |\n",
    "|-----------------------|--------------------------|--------------------------|\n",
    "| **Role**             | Data container           | Iterator for data loading |\n",
    "| **Access**           | Single sample            | Batches of samples       |\n",
    "| **Indexing**         | Yes (`dataset[idx]`)     | No                       |\n",
    "| **Batching**         | No                       | Yes                      |\n",
    "| **Shuffling**        | No                       | Yes                      |\n",
    "| **Parallel Loading** | No                       | Yes                      |"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ae52b79-61a5-4df2-84a2-198ebba751d1",
   "metadata": {},
   "source": [
    "## Example of very simple Dataset and DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0911c867-93ea-43bc-a216-158c10f028c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "edc10c8e-719d-474d-a102-b7f06e2f90fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 1: Define a simple dataset\n",
    "class SimpleDataset(Dataset):\n",
    "    \n",
    "    def __init__(self):\n",
    "        # Create some dummy data (e.g., 100 samples of 2D points)\n",
    "        self.inputs = torch.arange(10).view(-1, 2)  # 50 samples of [x, y] pairs\n",
    "        self.targets = torch.arange(5) \n",
    "        \n",
    "    def __len__(self):\n",
    "        # Number of samples in the dataset\n",
    "        return len(self.inputs)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        # Return a single sample at the given index\n",
    "        return self.inputs[idx], self.targets[idx]\n",
    "\n",
    "dataset = SimpleDataset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "940d1c10-8ddf-459b-8363-934469c59404",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 1\n",
      "Inputs: [[0 1]\n",
      " [6 7]]\n",
      "Target: [0 3]\n",
      "\n",
      "Batch 2\n",
      "Inputs: [[2 3]\n",
      " [8 9]]\n",
      "Target: [1 4]\n",
      "\n",
      "Batch 3\n",
      "Inputs: [[4 5]]\n",
      "Target: [2]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "batch_size = 2\n",
    "shuffle = True\n",
    "dataloader = DataLoader(dataset, batch_size=batch_size, shuffle=shuffle)\n",
    "for batch_idx, (inputs, target) in enumerate(dataloader):\n",
    "    print(f\"Batch {batch_idx + 1}\")\n",
    "    print(f\"Inputs: {inputs.numpy()}\")\n",
    "    print(f\"Target: {target.numpy()}\")\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "57589357-53e7-4c76-ba8c-bd18378f1fe1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 1\n",
      "Inputs: [[0 1]\n",
      " [2 3]\n",
      " [4 5]]\n",
      "Target: [0 1 2]\n",
      "\n",
      "Batch 2\n",
      "Inputs: [[6 7]\n",
      " [8 9]]\n",
      "Target: [3 4]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "batch_size = 3\n",
    "shuffle = False\n",
    "dataloader = DataLoader(dataset, batch_size=batch_size, shuffle=shuffle)\n",
    "for batch_idx, (inputs, target) in enumerate(dataloader):\n",
    "    print(f\"Batch {batch_idx + 1}\")\n",
    "    print(f\"Inputs: {inputs.numpy()}\")\n",
    "    print(f\"Target: {target.numpy()}\")\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7a64932-c8d8-46e5-ace4-15ab16b5876b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
